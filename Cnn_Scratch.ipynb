{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ca9bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\geniteam\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ef1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([\n",
    "    [45, 50],\n",
    "    [70, 65],\n",
    "    [85, 80],\n",
    "    [60, 58],\n",
    "    [40, 42],\n",
    "    [75, 70],\n",
    "    [90, 85],\n",
    "    [55, 60]\n",
    "])\n",
    "\n",
    "y = np.array([[48], [72], [88], [62], [44], [76], [91], [59]])\n",
    "\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y_mean = y.mean()\n",
    "y_std = y.std()\n",
    "y_norm = (y - y_mean) / y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92243246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Initial Weights and Biases:\n",
      "W1:\n",
      " [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "b1:\n",
      " [[0. 0. 0.]]\n",
      "W2:\n",
      " [[ 1.74481176]\n",
      " [-0.7612069 ]\n",
      " [ 0.3190391 ]]\n",
      "b2:\n",
      " [[0.]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "    \n",
    "np.random.seed(1)\n",
    "W1 = np.random.randn(2, 3)\n",
    "b1 = np.zeros((1, 3))\n",
    "\n",
    "W2 = np.random.randn(3, 1)\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "\n",
    "print(\"ðŸŽ¯ Initial Weights and Biases:\")\n",
    "print(\"W1:\\n\", W1)\n",
    "print(\"b1:\\n\", b1)\n",
    "print(\"W2:\\n\", W2)\n",
    "print(\"b2:\\n\", b2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdc8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    global Z1, A1, Z2, A2\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = Z2  # Linear activation for regression\n",
    "    return A2\n",
    "\n",
    "# ==== 7. Backward Pass ====\n",
    "def backward(X, y, output, lr=0.1):\n",
    "    global W1, W2, b1, b2\n",
    "    error = y - output\n",
    "    d_output = error  # Derivative of linear is 1\n",
    "\n",
    "    d_hidden = d_output.dot(W2.T) * sigmoid_derivative(A1)\n",
    "\n",
    "    W2 += A1.T.dot(d_output) * lr\n",
    "    b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
    "\n",
    "    W1 += X.T.dot(d_hidden) * lr\n",
    "    b1 += np.sum(d_hidden, axis=0, keepdims=True) * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7412f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted final scores:\n",
      "[[75.]\n",
      " [81.]\n",
      " [79.]\n",
      " [80.]\n",
      " [77.]\n",
      " [80.]\n",
      " [79.]\n",
      " [74.]]\n",
      "Actual final scores:\n",
      "[[48]\n",
      " [72]\n",
      " [88]\n",
      " [62]\n",
      " [44]\n",
      " [76]\n",
      " [91]\n",
      " [59]]\n"
     ]
    }
   ],
   "source": [
    "final_preds = forward(X)\n",
    "final_preds = final_preds * y_std + y_mean  # de-normalize\n",
    "\n",
    "print(\"Predicted final scores:\")\n",
    "print(final_preds.round())\n",
    "\n",
    "print(\"Actual final scores:\")\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5721f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“˜ Epoch 1\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[0.48396664]\n",
      " [0.80512569]\n",
      " [0.70751051]\n",
      " [0.75858197]\n",
      " [0.61637565]\n",
      " [0.74706529]\n",
      " [0.70772075]\n",
      " [0.42065639]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 1.90918818 -0.74729556 -0.51942635]\n",
      " [-0.78411087  0.72901815 -2.29315774]]\n",
      "b1:\n",
      " [[-0.20870246  0.09809526 -0.02013354]]\n",
      "W2:\n",
      " [[ 1.57823342]\n",
      " [-0.97605853]\n",
      " [-0.22031196]]\n",
      "b2:\n",
      " [[-0.52470029]]\n",
      "ðŸ“‰ Loss: 1.3011\n",
      "\n",
      "ðŸ“˜ Epoch 2\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-1.02853991]\n",
      " [-0.18893054]\n",
      " [ 0.14227534]\n",
      " [-0.56165923]\n",
      " [-1.00641974]\n",
      " [-0.05264787]\n",
      " [ 0.21001239]\n",
      " [-0.86274132]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.02154771 -0.85023088 -0.52199503]\n",
      " [-0.67182586  0.62418314 -2.29535237]]\n",
      "b1:\n",
      " [[-0.099014    0.01676662 -0.02789216]]\n",
      "W2:\n",
      " [[ 1.83257906]\n",
      " [-0.80090056]\n",
      " [-0.20426353]]\n",
      "b2:\n",
      " [[-0.1898352]]\n",
      "ðŸ“‰ Loss: 0.4678\n",
      "\n",
      "ðŸ“˜ Epoch 3\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-0.60061084]\n",
      " [ 0.47517174]\n",
      " [ 0.94274307]\n",
      " [-0.01288364]\n",
      " [-0.62690414]\n",
      " [ 0.66611973]\n",
      " [ 1.03693218]\n",
      " [-0.34871194]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.0865934  -0.90849198 -0.52362481]\n",
      " [-0.60338211  0.56383143 -2.29711253]]\n",
      "b1:\n",
      " [[-0.14490655  0.04677346 -0.02399286]]\n",
      "W2:\n",
      " [[ 1.83700165]\n",
      " [-0.89320734]\n",
      " [-0.38914965]]\n",
      "b2:\n",
      " [[-0.34302082]]\n",
      "ðŸ“‰ Loss: 0.1892\n",
      "\n",
      "ðŸ“˜ Epoch 4\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-1.05758663]\n",
      " [ 0.19723686]\n",
      " [ 0.80103724]\n",
      " [-0.40694559]\n",
      " [-1.10457843]\n",
      " [ 0.45409561]\n",
      " [ 0.91039591]\n",
      " [-0.73927078]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.12537724 -0.95004552 -0.52454584]\n",
      " [-0.56234123  0.51981115 -2.29830468]]\n",
      "b1:\n",
      " [[-0.11448387  0.02603918 -0.02776251]]\n",
      "W2:\n",
      " [[ 1.9352141 ]\n",
      " [-0.85972842]\n",
      " [-0.4099608 ]]\n",
      "b2:\n",
      " [[-0.24845924]]\n",
      "ðŸ“‰ Loss: 0.0888\n",
      "\n",
      "ðŸ“˜ Epoch 5\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-0.97560284]\n",
      " [ 0.38723581]\n",
      " [ 1.04844898]\n",
      " [-0.27492383]\n",
      " [-1.03770881]\n",
      " [ 0.67084377]\n",
      " [ 1.16460784]\n",
      " [-0.62109408]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.14810789 -0.97763874 -0.52468759]\n",
      " [-0.5356991   0.48956901 -2.29907452]]\n",
      "b1:\n",
      " [[-0.12520393  0.03335032 -0.02581105]]\n",
      "W2:\n",
      " [[ 1.95568497]\n",
      " [-0.89102067]\n",
      " [-0.47660587]]\n",
      "b2:\n",
      " [[-0.28463992]]\n",
      "ðŸ“‰ Loss: 0.0497\n",
      "\n",
      "ðŸ“˜ Epoch 6\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-1.11970856]\n",
      " [ 0.32260024]\n",
      " [ 1.04025274]\n",
      " [-0.38939165]\n",
      " [-1.19069513]\n",
      " [ 0.63350085]\n",
      " [ 1.16266895]\n",
      " [-0.73703775]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.16132466 -0.99660472 -0.52377275]\n",
      " [-0.51869777  0.46778105 -2.29896648]]\n",
      "b1:\n",
      " [[-0.11698615  0.02746324 -0.02714017]]\n",
      "W2:\n",
      " [[ 1.99393522]\n",
      " [-0.88649026]\n",
      " [-0.49419552]]\n",
      "b2:\n",
      " [[-0.25685889]]\n",
      "ðŸ“‰ Loss: 0.0337\n",
      "\n",
      "ðŸ“˜ Epoch 7\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-1.11367389]\n",
      " [ 0.37830269]\n",
      " [ 1.12380123]\n",
      " [-0.36144552]\n",
      " [-1.19095739]\n",
      " [ 0.70251421]\n",
      " [ 1.24925683]\n",
      " [-0.71414837]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.16807723 -1.00989964 -0.52231201]\n",
      " [-0.50752562  0.45155743 -2.29849769]]\n",
      "b1:\n",
      " [[-0.11994499  0.02899084 -0.02663356]]\n",
      "W2:\n",
      " [[ 2.0074663 ]\n",
      " [-0.89739717]\n",
      " [-0.52005629]]\n",
      "b2:\n",
      " [[-0.26422387]]\n",
      "ðŸ“‰ Loss: 0.0268\n",
      "\n",
      "ðŸ“˜ Epoch 8\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-1.1622481 ]\n",
      " [ 0.36477877]\n",
      " [ 1.13462787]\n",
      " [-0.39629314]\n",
      " [-1.24377264]\n",
      " [ 0.70057043]\n",
      " [ 1.26297239]\n",
      " [-0.75009183]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.17079358 -1.01926175 -0.52028646]\n",
      " [-0.50032975  0.43919105 -2.29756982]]\n",
      "b1:\n",
      " [[-0.11818603  0.02716957 -0.02713273]]\n",
      "W2:\n",
      " [[ 2.02285838]\n",
      " [-0.89789388]\n",
      " [-0.53037466]]\n",
      "b2:\n",
      " [[-0.25527825]]\n",
      "ðŸ“‰ Loss: 0.0237\n",
      "\n",
      "ðŸ“˜ Epoch 9\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-1.1676078 ]\n",
      " [ 0.38161388]\n",
      " [ 1.16517978]\n",
      " [-0.3919297 ]\n",
      " [-1.25221373]\n",
      " [ 0.72376947]\n",
      " [ 1.29526805]\n",
      " [-0.74735469]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.17075629 -1.02611328 -0.51795898]\n",
      " [-0.49565229  0.42929029 -2.29642609]]\n",
      "b1:\n",
      " [[-0.11954616  0.02736965 -0.02710753]]\n",
      "W2:\n",
      " [[ 2.02990475]\n",
      " [-0.90186163]\n",
      " [-0.54116055]]\n",
      "b2:\n",
      " [[-0.25595077]]\n",
      "ðŸ“‰ Loss: 0.0222\n",
      "\n",
      "ðŸ“˜ Epoch 10\n",
      "ðŸ”¹ Output of forward pass (normalized):\n",
      "[[-1.1850921 ]\n",
      " [ 0.37923702]\n",
      " [ 1.17382383]\n",
      " [-0.40313553]\n",
      " [-1.27196236]\n",
      " [ 0.72637466]\n",
      " [ 1.30549939]\n",
      " [-0.75886257]]\n",
      "ðŸ”§ Updated Weights and Biases:\n",
      "W1:\n",
      " [[ 2.16895774 -1.03120382 -0.51537219]\n",
      " [-0.49268323  0.42112492 -2.29507457]]\n",
      "b1:\n",
      " [[-0.11976064  0.02673963 -0.02736829]]\n",
      "W2:\n",
      " [[ 2.03623445]\n",
      " [-0.90268623]\n",
      " [-0.54668278]]\n",
      "b2:\n",
      " [[-0.25253901]]\n",
      "ðŸ“‰ Loss: 0.0214\n",
      "\n",
      "âœ… Final Predictions (Denormalized):\n",
      "[[48.]\n",
      " [74.]\n",
      " [87.]\n",
      " [61.]\n",
      " [47.]\n",
      " [79.]\n",
      " [89.]\n",
      " [55.]]\n",
      "ðŸŽ¯ Actual Final Scores:\n",
      "[[48]\n",
      " [72]\n",
      " [88]\n",
      " [62]\n",
      " [44]\n",
      " [76]\n",
      " [91]\n",
      " [59]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10  # keep small to observe clearly\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nðŸ“˜ Epoch {epoch+1}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    output = forward(X)\n",
    "    print(\"ðŸ”¹ Output of forward pass (normalized):\")\n",
    "    print(output)\n",
    "\n",
    "    # Backward pass\n",
    "    backward(X, y_norm, output, lr=0.1)\n",
    "\n",
    "    # Print updated weights after backprop\n",
    "    print(\"ðŸ”§ Updated Weights and Biases:\")\n",
    "    print(\"W1:\\n\", W1)\n",
    "    print(\"b1:\\n\", b1)\n",
    "    print(\"W2:\\n\", W2)\n",
    "    print(\"b2:\\n\", b2)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = np.mean(np.square(y_norm - output))\n",
    "    print(f\"ðŸ“‰ Loss: {loss:.4f}\")\n",
    "\n",
    "# ==== 9. Final Predictions ====\n",
    "print(\"\\nâœ… Final Predictions (Denormalized):\")\n",
    "preds = forward(X)\n",
    "preds = preds * y_std + y_mean\n",
    "print(preds.round())\n",
    "\n",
    "print(\"ðŸŽ¯ Actual Final Scores:\")\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
